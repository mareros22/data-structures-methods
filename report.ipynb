{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pytest\n",
    "from JuliaSet import calculate_z_serial_purepython\n",
    "from test_juliaset import test_calc_pure_python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia Set Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area of complex space to investigate\n",
    "x1, x2, y1, y2 = -1.8, 1.8, -1.8, 1.8\n",
    "c_real, c_imag = -0.62772, -.42193"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: PyTest with the Julia Set Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Testing with PyTest Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_calc_pure_python(desired_width=1000, max_iterations=300):\n",
    "    \"\"\"Create a list of complex coordinates (zs) and complex parameters (cs),\n",
    "    build Julia set\"\"\"\n",
    "    x_step = (x2 - x1) / desired_width\n",
    "    y_step = (y1 - y2) / desired_width\n",
    "    x = []\n",
    "    y = []\n",
    "    ycoord = y2\n",
    "    while ycoord > y1:\n",
    "        y.append(ycoord)\n",
    "        ycoord += y_step\n",
    "    xcoord = x1\n",
    "    while xcoord < x2:\n",
    "        x.append(xcoord)\n",
    "        xcoord += x_step\n",
    "    # build a list of coordinates and the initial condition for each cell.\n",
    "    # Note that our initial condition is a constant and could easily be removed,\n",
    "    # we use it to simulate a real-world scenario with several inputs to our\n",
    "    # function\n",
    "    zs = []\n",
    "    cs = []\n",
    "    for ycoord in y:\n",
    "        for xcoord in x:\n",
    "            zs.append(complex(xcoord, ycoord))\n",
    "            cs.append(complex(c_real, c_imag))\n",
    "\n",
    "    print(\"Length of x:\", len(x))\n",
    "    print(\"Total elements:\", len(zs))\n",
    "    start_time = time.time()\n",
    "    output = calculate_z_serial_purepython(max_iterations, zs, cs)\n",
    "    end_time = time.time()\n",
    "    secs = end_time - start_time\n",
    "    print(calculate_z_serial_purepython.__name__ + \" took\", secs, \"seconds\")\n",
    "\n",
    "    # This sum is expected for a 1000^2 grid with 300 iterations\n",
    "    # It ensures that our code evolves exactly as we'd intended\n",
    "    print(\"new sum: \", sum(output))\n",
    "    assert sum(output) == 33219980"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.8, pytest-8.3.4, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\phoeb\\OneDrive\\Documents\\KTH\\HPC\\data-structures-methods\n",
      "plugins: anyio-4.6.2.post1\n",
      "collected 1 item\n",
      "\n",
      "test_juliaset.py \u001b[32m.\u001b[0m\u001b[32m                                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 4.92s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest test_juliaset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Testing with Varying Iterations & Grid Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test with varying iterations and grid points, we would use a parameterized test. This is shown through `@pytest.mark.parameterize()`, and the parameters are argnames and argvalues for the string names and values respectively. This allows us to assert different expected values based on the parameters and test each of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "@pytest.mark.parameterize('desired_width, max_iterations, expected', [(1000, 300, 33219980)])\n",
    "def test_calc_pure_python_param(desired_width, max_iterations, expected):\n",
    "    \"\"\"Create a list of complex coordinates (zs) and complex parameters (cs),\n",
    "    build Julia set\"\"\"\n",
    "    x_step = (x2 - x1) / desired_width\n",
    "    y_step = (y1 - y2) / desired_width\n",
    "    x = []\n",
    "    y = []\n",
    "    ycoord = y2\n",
    "    while ycoord > y1:\n",
    "        y.append(ycoord)\n",
    "        ycoord += y_step\n",
    "    xcoord = x1\n",
    "    while xcoord < x2:\n",
    "        x.append(xcoord)\n",
    "        xcoord += x_step\n",
    "    # build a list of coordinates and the initial condition for each cell.\n",
    "    # Note that our initial condition is a constant and could easily be removed,\n",
    "    # we use it to simulate a real-world scenario with several inputs to our\n",
    "    # function\n",
    "    zs = []\n",
    "    cs = []\n",
    "    for ycoord in y:\n",
    "        for xcoord in x:\n",
    "            zs.append(complex(xcoord, ycoord))\n",
    "            cs.append(complex(c_real, c_imag))\n",
    "\n",
    "    print(\"Length of x:\", len(x))\n",
    "    print(\"Total elements:\", len(zs))\n",
    "    start_time = time.time()\n",
    "    output = calculate_z_serial_purepython(max_iterations, zs, cs)\n",
    "    end_time = time.time()\n",
    "    secs = end_time - start_time\n",
    "    print(calculate_z_serial_purepython.__name__ + \" took\", secs, \"seconds\")\n",
    "\n",
    "    # This sum is expected for a 1000^2 grid with 300 iterations\n",
    "    # It ensures that our code evolves exactly as we'd intended\n",
    "    print(\"new sum: \", sum(output))\n",
    "    assert sum(output) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.8, pytest-8.3.4, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\phoeb\\OneDrive\\Documents\\KTH\\HPC\\data-structures-methods\n",
      "plugins: anyio-4.6.2.post1\n",
      "collected 1 item\n",
      "\n",
      "test_juliaset_param.py \u001b[32m.\u001b[0m\u001b[32m                                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 4.84s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest test_juliaset_param.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Python DGEMM Benchmark Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Implementing DGEMM with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_np = np.ones((3, 3), dtype=np.double)\n",
    "b_np = np.ones((3, 3), dtype=np.double)\n",
    "c_np = np.ones((3, 3), dtype=np.double)\n",
    "expected_np = np.array([[4,4,4],[4,4,4],[4,4,4]])\n",
    "\n",
    "def dgemm_numpy(a, b, c):\n",
    "  N = a.shape[0]\n",
    "  for i in range(N):\n",
    "    for j in range(N):\n",
    "      for k in range(N):\n",
    "        c[i][j] = c[i][j] + a[i][k] * b[k][j]\n",
    "  return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Unit Test for DGEMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dgemm():\n",
    "  assert np.array_equal(dgemm_numpy(a_np,b_np,c_np), expected_np) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.8, pytest-8.3.4, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\phoeb\\OneDrive\\Documents\\KTH\\HPC\\data-structures-methods\n",
      "plugins: anyio-4.6.2.post1\n",
      "collected 1 item\n",
      "\n",
      "test_dgemm.py \u001b[32m.\u001b[0m\u001b[32m                                                          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest test_dgemm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size | Avg. Time (s) | Std. Dev. (s)\n",
      "------------------------------------------\n",
      "    10      |   0.000400    |   0.000490  \n",
      "    50      |   0.067988    |   0.009108  \n",
      "    100     |   0.488158    |   0.006455  \n",
      "    200     |   4.259108    |   0.131729  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def dgemm_numpy(a, b, c):\n",
    "    N = a.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                c[i][j] += a[i][k] * b[k][j]\n",
    "    return c\n",
    "\n",
    "def measure_execution_time(matrix_size, runs=5):\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        # Initialize matrices with random values\n",
    "        a = np.ones((matrix_size, matrix_size), dtype=np.double)\n",
    "        b = np.ones((matrix_size, matrix_size), dtype=np.double)\n",
    "        c = np.zeros((matrix_size, matrix_size), dtype=np.double)\n",
    "\n",
    "        # Measure execution time\n",
    "        start_time = time.time()\n",
    "        dgemm_numpy(a, b, c)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    avg_time = np.mean(times)\n",
    "    std_dev = np.std(times)\n",
    "    return avg_time, std_dev\n",
    "\n",
    "# Testing with different matrix sizes\n",
    "matrix_sizes = [10, 50, 100, 200]  # You can increase these sizes for larger benchmarks\n",
    "results = []\n",
    "\n",
    "for size in matrix_sizes:\n",
    "    avg_time, std_dev = measure_execution_time(size)\n",
    "    results.append((size, avg_time, std_dev))\n",
    "\n",
    "# Print results\n",
    "print(\"Matrix Size | Avg. Time (s) | Std. Dev. (s)\")\n",
    "print(\"------------------------------------------\")\n",
    "for size, avg, std in results:\n",
    "    print(f\"{size:^11} | {avg:^13.6f} | {std:^12.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation with array: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "\n",
    "def dgemm_array(a, b, c, N):\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                c[i][j] += a[i][k] * b[k][j]\n",
    "    return c\n",
    "\n",
    "# Helper function to create 2D arrays\n",
    "def create_2d_array(size):\n",
    "    return [array.array('d', [0] * size) for _ in range(size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation using list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgemm_list(a, b, c):\n",
    "    N = len(a)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                c[i][j] += a[i][k] * b[k][j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measurement Code LIST, ARRAY, NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code handles and benchmarks multiple implementations sequentially in the same script. If the system runs other background processes or has load variations during the benchmarking process, these might disproportionately affect one implementation’s results. Furthermore, timing overhead might be added due to the use of lambdas for the array implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementation | Matrix Size | Avg. Time (s) | Std. Dev. (s)\n",
      "-----------------------------------------------------------\n",
      "    list      |     10      |   0.000000    |   0.000000  \n",
      "    array     |     10      |   0.000000    |   0.000000  \n",
      "    numpy     |     10      |   0.000855    |   0.000439  \n",
      "    list      |     50      |   0.008387    |   0.003362  \n",
      "    array     |     50      |   0.018179    |   0.002997  \n",
      "    numpy     |     50      |   0.068648    |   0.010827  \n",
      "    list      |     100     |   0.061487    |   0.005221  \n",
      "    array     |     100     |   0.118956    |   0.006789  \n",
      "    numpy     |     100     |   0.524995    |   0.005175  \n",
      "    list      |     200     |   0.503359    |   0.023612  \n",
      "    array     |     200     |   0.808957    |   0.008360  \n",
      "    numpy     |     200     |   3.961747    |   0.066757  \n",
      "    list      |     400     |   4.285885    |   0.025221  \n",
      "    array     |     400     |   7.265540    |   0.079518  \n",
      "    numpy     |     400     |   32.548607   |   0.272234  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Measure execution time for different implementations\n",
    "def measure_time_implementation(implementation, matrix_size, runs=5):\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        if implementation == \"list\":\n",
    "            # Initialize matrices as lists\n",
    "            a = [[1.0] * matrix_size for _ in range(matrix_size)]\n",
    "            b = [[1.0] * matrix_size for _ in range(matrix_size)]\n",
    "            c = [[0.0] * matrix_size for _ in range(matrix_size)]\n",
    "            func = dgemm_list\n",
    "        elif implementation == \"array\":\n",
    "            # Initialize matrices as arrays\n",
    "            a = create_2d_array(matrix_size)\n",
    "            b = create_2d_array(matrix_size)\n",
    "            c = create_2d_array(matrix_size)\n",
    "            for i in range(matrix_size):\n",
    "                for j in range(matrix_size):\n",
    "                    a[i][j] = b[i][j] = 1.0\n",
    "            func = lambda a, b, c: dgemm_array(a, b, c, matrix_size)\n",
    "        elif implementation == \"numpy\":\n",
    "            # Initialize matrices as NumPy arrays\n",
    "            a = np.ones((matrix_size, matrix_size), dtype=np.double)\n",
    "            b = np.ones((matrix_size, matrix_size), dtype=np.double)\n",
    "            c = np.zeros((matrix_size, matrix_size), dtype=np.double)\n",
    "            func = dgemm_numpy\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported implementation\")\n",
    "\n",
    "        # Measure time\n",
    "        start_time = time.time()\n",
    "        func(a, b, c)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    avg_time = np.mean(times)\n",
    "    std_dev = np.std(times)\n",
    "    return avg_time, std_dev\n",
    "\n",
    "# Compare implementations\n",
    "implementations = [\"list\", \"array\", \"numpy\"]\n",
    "matrix_sizes = [10, 50, 100, 200, 400]  # You can extend these sizes as needed\n",
    "results = []\n",
    "\n",
    "for size in matrix_sizes:\n",
    "    for impl in implementations:\n",
    "        avg_time, std_dev = measure_time_implementation(impl, size)\n",
    "        results.append((impl, size, avg_time, std_dev))\n",
    "\n",
    "# Print results\n",
    "print(\"Implementation | Matrix Size | Avg. Time (s) | Std. Dev. (s)\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "for impl, size, avg, std in results:\n",
    "    print(f\"{impl:^13} | {size:^11} | {avg:^13.6f} | {std:^12.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the computational performance, e.g., the std, vary with increasing the size of the matrices, and why so?\n",
    "\n",
    "### 1. Average Time Increases with Matrix Size:\n",
    "As the matrix size increases, the average execution time grows significantly for all implementations (list, array, and NumPy).\n",
    "This is expected because the computational complexity of matrix multiplication is $O(N^3)$, meaning the number of operations grows cubically with the matrix size N.\n",
    "### 2.Standard Deviation Trends:\n",
    "For small matrices (e.g., 10x10), the std. dev. is relatively small for all implementations.\n",
    "As the matrix size increases, the std. dev. generally increases, but the rate of increase varies across implementations.\n",
    "NumPy exhibits a higher std. dev. compared to lists and arrays, especially for larger matrices (e.g., 400x400).\n",
    "### 3. Relative Performance:\n",
    "For small matrices, the list implementation is the fastest, followed by arrays, and then NumPy. This trend stays consistent over increasing matrix size. \n",
    "For larger matrices, NumPy becomes significantly slower compared to lists and arrays, despite being optimized for numerical computations. This is likely due to NumPy beeing optimized for vectorized operations, but the implementation of DGEMM in this exercise uses explicit Python loops (for i, for j, for k). This negates the benefits of NumPy's vectorization and introduces significant overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.4 \n",
    "To calculate the FLOPS/s (floating-point operations per second), we first need to determine the number of floating-point operations (FLOPs) performed in the DGEMM operation. Then we divide the total number of FLOPs by the average time taken.\n",
    "\n",
    "In DGEMM, the operation is: \n",
    "$C[i][j] = C[i][j] + A[i][k] \\times B[k][j] $\n",
    "- The operation involves:\n",
    "\t- 1 multiplication:  A[i][k] \\times B[k][j] \n",
    "\t- 1 addition:  C[i][j] + \\text{result of multiplication} \n",
    "\t- Total FLOPs per iteration of the innermost loop: 2 FLOPs\n",
    "\n",
    "The total number of iterations across the nested loops is $N^3$, where $N$ is the matrix size. Therefore:\n",
    "\n",
    "$\\text{Total FLOPs} = 2 \\times N^3$\n",
    "\n",
    "\n",
    "The FLOPS/s for a given implementation is:\n",
    "\n",
    "$\\text{FLOPS/s} = \\frac{\\text{Total FLOPs}}{\\text{Avg. Time (s)}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementation | Matrix Size | Total FLOP(s)  | FLOPS/s\n",
      "---------------------------------------------------------\n",
      "    list      |     10      |    2000     | 1.98e+07\n",
      "    array     |     10      |    2000     | 1.01e+07\n",
      "    numpy     |     10      |    2000     | 2.60e+06\n",
      "    list      |     50      |   250000    | 1.59e+07\n",
      "    array     |     50      |   250000    | 2.33e+07\n",
      "    numpy     |     50      |   250000    | 5.24e+06\n",
      "    list      |     100     |   2000000   | 4.16e+07\n",
      "    array     |     100     |   2000000   | 2.34e+07\n",
      "    numpy     |     100     |   2000000   | 5.36e+06\n",
      "    list      |     200     |  16000000   | 4.16e+07\n",
      "    array     |     200     |  16000000   | 2.39e+07\n",
      "    numpy     |     200     |  16000000   | 5.46e+06\n",
      "    list      |     400     |  128000000  | 4.11e+07\n",
      "    array     |     400     |  128000000  | 2.27e+07\n",
      "    numpy     |     400     |  128000000  | 5.32e+06\n"
     ]
    }
   ],
   "source": [
    "def calculate_flops(matrix_size, avg_time):\n",
    "    # Calculate the total number of FLOPs\n",
    "    total_flops = 2 * (matrix_size ** 3)\n",
    "    # Calculate FLOPS/s\n",
    "    flops_per_second = total_flops / avg_time\n",
    "    return total_flops, flops_per_second\n",
    "\n",
    "# Timing results\n",
    "results = [\n",
    "    (\"list\", 10, 0.000101),\n",
    "    (\"array\", 10, 0.000199),\n",
    "    (\"numpy\", 10, 0.000768),\n",
    "    (\"list\", 50, 0.015739),\n",
    "    (\"array\", 50, 0.010727),\n",
    "    (\"numpy\", 50, 0.047675),\n",
    "    (\"list\", 100, 0.048073),\n",
    "    (\"array\", 100, 0.085522),\n",
    "    (\"numpy\", 100, 0.372809),\n",
    "    (\"list\", 200, 0.384661),\n",
    "    (\"array\", 200, 0.668303),\n",
    "    (\"numpy\", 200, 2.929246),\n",
    "    (\"list\", 400, 3.115510),\n",
    "    (\"array\", 400, 5.645596),\n",
    "    (\"numpy\", 400, 24.057626),\n",
    "]\n",
    "\n",
    "# Calculate FLOPS/s for each result\n",
    "print(\"Implementation | Matrix Size | Total FLOP(s)  | FLOPS/s\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for impl, size, avg_time in results:\n",
    "    total_flops, flops_per_second = calculate_flops(size, avg_time)\n",
    "    print(f\"{impl:^13} | {size:^11} | {total_flops:^11} | {flops_per_second:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to Theoretical Peak Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituding values for Mac Pro 2020 M1 chip: \n",
    "\t•\tClock Frequency = 3.2 GHz = 3.2 × 10⁹ cycles/second.\n",
    "\t•\tFLOPs per Cycle = 2 (double precision).\n",
    "\t•\tNumber of High-Performance Cores = 4.\n",
    "\n",
    "$\\text{Peak FLOPS/s} = 3.2 \\times 10^9 \\times 2 \\times 4 = 25.6 \\, \\text{GFLOPS (double precision)} $\n",
    "\n",
    "For single precision (32-bit floating-point), NEON can handle 4 single-precision numbers per cycle per core:\n",
    "\n",
    "$\\text{Peak FLOPS/s (single precision)} = 3.2 \\times 10^9 \\times 4 \\times 4 = 51.2 \\, \\text{GFLOPS}$\n",
    "\n",
    "\n",
    "The theoretical peak performance of the Apple M1 chip at 25.6 GFLOPS (double precision) far exceeds the actual measured performance, indicating that real-world DGEMM implementations face significant bottlenecks, such as memory bandwidth limitations, system overhead, and non-ideal utilization of vectorized instructions. This gap highlights the challenges in achieving the full computational potential of the hardware, as practical workloads rarely operate at maximum efficiency due to these constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Write about caching - why some avg times are 0, second time running code values become 0, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size: 10x10\n",
      "Custom DGEMM - Avg. Time: 0.001273s, Std. Dev.: 0.001109s\n",
      "NumPy matmul - Avg. Time: 0.000000s, Std. Dev.: 0.000000s\n",
      "\n",
      "Matrix Size: 50x50\n",
      "Custom DGEMM - Avg. Time: 0.091253s, Std. Dev.: 0.009511s\n",
      "NumPy matmul - Avg. Time: 0.000000s, Std. Dev.: 0.000000s\n",
      "\n",
      "Matrix Size: 100x100\n",
      "Custom DGEMM - Avg. Time: 0.727348s, Std. Dev.: 0.019342s\n",
      "NumPy matmul - Avg. Time: 0.000000s, Std. Dev.: 0.000000s\n",
      "\n",
      "Matrix Size: 200x200\n",
      "Custom DGEMM - Avg. Time: 5.743056s, Std. Dev.: 0.188019s\n",
      "NumPy matmul - Avg. Time: 0.001190s, Std. Dev.: 0.001702s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Custom DGEMM implementation\n",
    "def dgemm_custom(a, b, c):\n",
    "    N = a.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                c[i][j] += a[i][k] * b[k][j]\n",
    "    return c\n",
    "\n",
    "# Function to measure execution time\n",
    "def measure_execution_time(func, a, b, c, runs=5):\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        start_time = time.time()\n",
    "        func(a, b, c)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "    avg_time = np.mean(times)\n",
    "    std_dev = np.std(times)\n",
    "    return avg_time, std_dev\n",
    "\n",
    "# Function to benchmark both implementations\n",
    "def benchmark(matrix_size, runs=5):\n",
    "    # Initialize matrices\n",
    "    a = np.random.rand(matrix_size, matrix_size).astype(np.double)\n",
    "    b = np.random.rand(matrix_size, matrix_size).astype(np.double)\n",
    "    c_custom = np.zeros((matrix_size, matrix_size), dtype=np.double)\n",
    "    c_numpy = np.zeros((matrix_size, matrix_size), dtype=np.double)\n",
    "\n",
    "    # Measure custom DGEMM\n",
    "    avg_time_custom, std_dev_custom = measure_execution_time(dgemm_custom, a, b, c_custom, runs)\n",
    "\n",
    "    # Measure NumPy matmul\n",
    "    avg_time_numpy, std_dev_numpy = measure_execution_time(lambda x, y, z: np.matmul(x, y, out=z), a, b, c_numpy, runs)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Matrix Size: {matrix_size}x{matrix_size}\")\n",
    "    print(f\"Custom DGEMM - Avg. Time: {avg_time_custom:.6f}s, Std. Dev.: {std_dev_custom:.6f}s\")\n",
    "    print(f\"NumPy matmul - Avg. Time: {avg_time_numpy:.6f}s, Std. Dev.: {std_dev_numpy:.6f}s\")\n",
    "    print()\n",
    "\n",
    "# Run benchmark for different matrix sizes\n",
    "matrix_sizes = [10, 50, 100, 200]\n",
    "for size in matrix_sizes:\n",
    "    benchmark(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size: 10x10\n",
      "Custom DGEMM - Avg. Time: 0.001040s, Std. Dev.: 0.001327s, FLOPS: 1.92e+06\n",
      "NumPy matmul - Avg. Time: 0.000000s, Std. Dev.: 0.000000s, FLOPS: 0.00e+00\n",
      "\n",
      "Matrix Size: 50x50\n",
      "Custom DGEMM - Avg. Time: 0.085787s, Std. Dev.: 0.003505s, FLOPS: 2.91e+06\n",
      "NumPy matmul - Avg. Time: 0.000000s, Std. Dev.: 0.000000s, FLOPS: 0.00e+00\n",
      "\n",
      "Matrix Size: 100x100\n",
      "Custom DGEMM - Avg. Time: 0.655219s, Std. Dev.: 0.011645s, FLOPS: 3.05e+06\n",
      "NumPy matmul - Avg. Time: 0.000000s, Std. Dev.: 0.000000s, FLOPS: 0.00e+00\n",
      "\n",
      "Matrix Size: 200x200\n",
      "Custom DGEMM - Avg. Time: 5.218712s, Std. Dev.: 0.117734s, FLOPS: 3.07e+06\n",
      "NumPy matmul - Avg. Time: 0.000000s, Std. Dev.: 0.000000s, FLOPS: 0.00e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Custom DGEMM implementation\n",
    "def dgemm_custom(a, b, c):\n",
    "    N = a.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                c[i][j] += a[i][k] * b[k][j]\n",
    "    return c\n",
    "\n",
    "# Function to measure execution time\n",
    "def measure_execution_time(func, a, b, c, runs=5):\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        start_time = time.time()\n",
    "        func(a, b, c)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "    avg_time = np.mean(times)\n",
    "    std_dev = np.std(times)\n",
    "    return avg_time, std_dev\n",
    "\n",
    "# Function to calculate FLOPS\n",
    "def calculate_flops(matrix_size, avg_time):\n",
    "    total_flops = 2 * (matrix_size ** 3)  # 2 FLOPs per iteration (1 multiply + 1 add)\n",
    "    flops_per_second = total_flops / avg_time if avg_time > 0 else 0\n",
    "    return total_flops, flops_per_second\n",
    "\n",
    "# Function to benchmark both implementations and compute FLOPS\n",
    "def benchmark(matrix_size, runs=5):\n",
    "    # Initialize matrices\n",
    "    a = np.random.rand(matrix_size, matrix_size).astype(np.double)\n",
    "    b = np.random.rand(matrix_size, matrix_size).astype(np.double)\n",
    "    c_custom = np.zeros((matrix_size, matrix_size), dtype=np.double)\n",
    "    c_numpy = np.zeros((matrix_size, matrix_size), dtype=np.double)\n",
    "\n",
    "    # Measure custom DGEMM\n",
    "    avg_time_custom, std_dev_custom = measure_execution_time(dgemm_custom, a, b, c_custom, runs)\n",
    "    total_flops_custom, flops_custom = calculate_flops(matrix_size, avg_time_custom)\n",
    "\n",
    "    # Measure NumPy matmul\n",
    "    avg_time_numpy, std_dev_numpy = measure_execution_time(lambda x, y, z: np.matmul(x, y, out=z), a, b, c_numpy, runs)\n",
    "    total_flops_numpy, flops_numpy = calculate_flops(matrix_size, avg_time_numpy)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Matrix Size: {matrix_size}x{matrix_size}\")\n",
    "    print(f\"Custom DGEMM - Avg. Time: {avg_time_custom:.6f}s, Std. Dev.: {std_dev_custom:.6f}s, FLOPS: {flops_custom:.2e}\")\n",
    "    print(f\"NumPy matmul - Avg. Time: {avg_time_numpy:.6f}s, Std. Dev.: {std_dev_numpy:.6f}s, FLOPS: {flops_numpy:.2e}\")\n",
    "    print()\n",
    "\n",
    "# Run benchmark for different matrix sizes\n",
    "matrix_sizes = [10, 50, 100, 200]\n",
    "for size in matrix_sizes:\n",
    "    benchmark(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy’s matmul not only leverages the full capabilities of the M1 chip but also surpasses the theoretical peak due to highly optimized, hardware-specific operations. This demonstrates that for computationally intensive tasks, using optimized libraries like BLAS is critical for achieving performance close to or beyond theoretical limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Experiment with Python Debugger Reflection\n",
    "\n",
    "By using a debugger, the programmer is able to use many functionalities that help answer questions about the code that might not be obvious when running through the code. Some of the advantages include being able to go through each line of code and decide to either enter into the function call to help trace your code, or step over it to get to a different faulty spot.  While you are running in the debugger, you can also inspect the variables values, set breakpoints, and look at how the stack is ordered. If you want, you can also see the files in your code that are running and what they look like. This ability to inspect the program state during execution can be very helpful. If something is going wrong, the programmer can see exactly which function or even which instruction caused the state to deviate from what they expect. Some challenges that we found were that it was quite difficult to get started with the debugger. While the installation and running of it was simple, it was difficult to know exactly what to do in order to inspect our code properly. There are many capabilities that the debugger offers, it is just difficult to know which ones to use and where. It's a useful tool once a programmer is proficient with it but there is a learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Exercise\n",
    "### Performance Analysis and Optimization of the Game of Life Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Module game_of_life\n",
      "game_of_life.py:11:31: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:24:38: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:25:38: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:59:28: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:64:70: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:66:62: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:67:62: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:68:74: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:95:0: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:100:0: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:127:18: C0303: Trailing whitespace (trailing-whitespace)\n",
      "game_of_life.py:136:0: C0304: Final newline missing (missing-final-newline)\n",
      "game_of_life.py:80:0: R1707: Disallow trailing comma tuple (trailing-comma-tuple)\n",
      "game_of_life.py:9:0: C0410: Multiple imports on one line (sys, argparse) (multiple-imports)\n",
      "game_of_life.py:12:0: R0402: Use 'from matplotlib import animation' instead (consider-using-from-import)\n",
      "game_of_life.py:18:0: C0103: Function name \"randomGrid\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:18:15: C0103: Argument name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:22:0: C0103: Function name \"addGlider\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:29:0: C0103: Function name \"addGosperGliderGun\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:57:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
      "game_of_life.py:57:11: C0103: Argument name \"frameNum\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:57:32: C0103: Argument name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:60:4: C0103: Variable name \"newGrid\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:57:11: W0613: Unused argument 'frameNum' (unused-argument)\n",
      "game_of_life.py:83:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
      "game_of_life.py:97:4: C0103: Variable name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:99:8: C0103: Variable name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:102:4: C0103: Variable name \"updateInterval\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:104:8: C0103: Variable name \"updateInterval\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:9:0: W0611: Unused import sys (unused-import)\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Your code has been rated at 6.05/10 (previous run: 7.79/10, -1.74)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install pylint\n",
    "! pylint game_of_life.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install autopep8\n",
    "! autopep8 -i game_of_life.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Module game_of_life\n",
      "game_of_life.py:85:0: R1707: Disallow trailing comma tuple (trailing-comma-tuple)\n",
      "game_of_life.py:13:0: R0402: Use 'from matplotlib import animation' instead (consider-using-from-import)\n",
      "game_of_life.py:20:0: C0103: Function name \"randomGrid\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:20:15: C0103: Argument name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:25:0: C0103: Function name \"addGlider\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:33:0: C0103: Function name \"addGosperGliderGun\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:62:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
      "game_of_life.py:62:11: C0103: Argument name \"frameNum\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:62:32: C0103: Argument name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:65:4: C0103: Variable name \"newGrid\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:62:11: W0613: Unused argument 'frameNum' (unused-argument)\n",
      "game_of_life.py:90:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
      "game_of_life.py:105:4: C0103: Variable name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:107:8: C0103: Variable name \"N\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:110:4: C0103: Variable name \"updateInterval\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:112:8: C0103: Variable name \"updateInterval\" doesn't conform to snake_case naming style (invalid-name)\n",
      "game_of_life.py:9:0: W0611: Unused import sys (unused-import)\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Your code has been rated at 7.79/10 (previous run: 6.05/10, +1.74)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pylint game_of_life.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont need to run this again\n",
    "# sphinx-quickstart\n",
    "# sphinx-build -M html source build\n",
    "# TO UPDATE THE HTML FILE\n",
    "# make html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
